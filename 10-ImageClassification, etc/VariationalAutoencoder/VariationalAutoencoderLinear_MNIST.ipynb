{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [],
   "source": [
    "#     This program is free software: you can redistribute it and/or modify\n",
    "#     it under the terms of the GNU General Public License as published by\n",
    "#     the Free Software Foundation, either version 3 of the License, or\n",
    "#     (at your option) any later version.\n",
    "#\n",
    "#     This program is distributed in the hope that it will be useful,\n",
    "#     but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
    "#     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n",
    "#     GNU General Public License for more details.\n",
    "#\n",
    "#     You should have received a copy of the GNU General Public License\n",
    "#     along with this program.  If not, see <https://www.gnu.org/licenses/>.\n",
    "\n",
    "#     Written by Charalambos (Charis) Poullis - www.poullis.org"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [],
   "source": [
    "#Import all necessary libraries\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "#progress bar functionality\n",
    "import tqdm\n",
    "#plotting etc\n",
    "import matplotlib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "#random number generator\n",
    "import random\n",
    "\n",
    "# There is a weird crash in Python 3.9 causing the kernel to restart when using matplotlib\n",
    "# To test if you have the same issue uncomment the following command. If it works, then you don't need the subsequent 2 lines (import os, KMP)\n",
    "#plt.subplot()\n",
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset: Dataset MNIST\n",
      "    Number of datapoints: 60000\n",
      "    Root location: ../data\n",
      "    Split: Train\n",
      "    StandardTransform\n",
      "Transform: ToTensor()\n",
      "Testing dataset: Dataset MNIST\n",
      "    Number of datapoints: 10000\n",
      "    Root location: ../data\n",
      "    Split: Test\n",
      "    StandardTransform\n",
      "Transform: ToTensor()\n"
     ]
    }
   ],
   "source": [
    "#Set the path for the datasets\n",
    "DATASET_PATH = \"../data\"\n",
    "\n",
    "#MNIST image size 1x28x28\n",
    "CHANNELS = 1\n",
    "WIDTH = 28\n",
    "HEIGHT = 28\n",
    "\n",
    "#Download the training dataset: CIFAR10\n",
    "training_dataset = torchvision.datasets.MNIST(root=DATASET_PATH,\n",
    "                                                train=True,\n",
    "                                                download=True,\n",
    "                                                transform=torchvision.transforms.ToTensor())\n",
    "print('Training dataset:', training_dataset)\n",
    "\n",
    "#Download the testing dataset: CIFAR10\n",
    "testing_dataset = torchvision.datasets.MNIST(root=DATASET_PATH,\n",
    "                                               train=False,\n",
    "                                               download=True,\n",
    "                                               transform=torchvision.transforms.ToTensor())\n",
    "print('Testing dataset:', testing_dataset)  \n",
    "\n",
    "#Create a list with user-friendly names for each label\n",
    "labels=[\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [],
   "source": [
    "#This function takes a CIFAR dataset and splits it into two numpy arrays containing\n",
    "#the images and labels, respectively\n",
    "\n",
    "def splitDataset(dataset, channels, width, height):\n",
    "    #Divide the datasets into images and labels\n",
    "    x, y = dataset[0]\n",
    "    \n",
    "    shape = [(i, *j) for i, j in [(len(dataset), x.shape)]][0]\n",
    "    images = np.zeros(shape)\n",
    "    labels = np.zeros((len(dataset), 1))\n",
    "    \n",
    "    for i in range(len(dataset)):\n",
    "        x,y = dataset[i]\n",
    "        images[i] = x\n",
    "        labels[i] = y\n",
    "        \n",
    "    images = np.reshape(images, (len(dataset), channels, width, height))\n",
    "    labels = np.reshape(labels, (len(dataset), 1))\n",
    "    return images, labels"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training images: 60000, Training labels: 60000\n",
      "Testing images: 10000, Testing labels: 10000\n"
     ]
    }
   ],
   "source": [
    "#Divide the training datasets into images and labels; this is needed later to randomly index from the arrays\n",
    "training_images, training_labels = splitDataset(training_dataset, CHANNELS, WIDTH, HEIGHT)\n",
    "#Do the same for the testing dataset\n",
    "testing_images, testing_labels = splitDataset(testing_dataset, CHANNELS, WIDTH, HEIGHT)   \n",
    "\n",
    "print(f'Training images: {len(training_images)}, Training labels: {len(training_labels)}')\n",
    "print(f'Testing images: {len(testing_images)}, Testing labels: {len(testing_labels)}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [],
   "source": [
    "#Define the autoencoder; This is a simple autoencoder with 2 convolutional layers in the encoder, and 2 convolutional layers in the decoder\n",
    "#Put simply, an autoencoder learns to reconstruct the input\n",
    "class MyAutoencoder (torch.nn.Module):\n",
    "    def __init__(self, channels, width, height):\n",
    "        super(MyAutoencoder, self).__init__()\n",
    "\n",
    "        #The patch size\n",
    "        self.channels = channels\n",
    "        self.width = width\n",
    "        self.height = height\n",
    "\n",
    "        #The latent dimensions\n",
    "        self.latent_space_dims = 4\n",
    "\n",
    "        #Define a unit Gaussian distribution to be used for sampling\n",
    "        self.unit_gaussian_distribution = torch.distributions.normal.Normal(loc=torch.tensor(0.0).to(device),\n",
    "                                                                            scale=torch.tensor(1.0).to(device))\n",
    "\n",
    "        #The KL divergence\n",
    "        self.KL_div = torch.tensor(0.0)\n",
    "\n",
    "        #Encoder\n",
    "        self.encoder = torch.nn.Sequential(\n",
    "            torch.nn.Linear(in_features=self.channels*self.width*self.height, out_features=512),\n",
    "            torch.nn.ReLU()\n",
    "        )\n",
    "\n",
    "        #μ\n",
    "        self.mu = torch.nn.Linear(in_features=512, out_features=self.latent_space_dims)\n",
    "        #σ\n",
    "        self.sigma = torch.nn.Linear(in_features=512, out_features=self.latent_space_dims)\n",
    "\n",
    "        #Decoder\n",
    "        self.decoder = torch.nn.Sequential(\n",
    "            torch.nn.Linear(in_features=self.latent_space_dims, out_features=512),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(in_features=512, out_features=self.channels*self.width*self.height),\n",
    "\n",
    "            #At this point the range of the output value is unbound. Let's use Maps the value to the range [0,1] which is expected for colors\n",
    "            torch.nn.Sigmoid()\n",
    "        )\n",
    "        return\n",
    "\n",
    "    def getKLdiv(self):\n",
    "        return self.KL_div\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.reshape(x, (-1, self.channels*self.width*self.height))\n",
    "        #Feed-forward through the encoder\n",
    "        result = self.encoder(x)\n",
    "        \n",
    "        #Sample z using the Gaussian distribution\n",
    "        mu = self.mu(result)\n",
    "        sigma = torch.exp(self.sigma(result)) #self.sigma(.) can return negative values. We add the exponent to keep the values positive. Otherwise, what is the meaning of having negative standard deviation σ?\n",
    "        z = mu + sigma*self.unit_gaussian_distribution.sample(mu.shape)\n",
    "\n",
    "        #Feed-forward through the decoder\n",
    "        result = self.decoder(z)\n",
    "        result = torch.reshape(result, (-1, self.channels, self.width, self.height))\n",
    "        #Calculate the closed form KL divergence between 2 Gaussians; you want the learnt (μ,σ) to resemble a zero-mean Gaussian distribution with standard deviation of 1.0\n",
    "        self.KL_div = torch.sum(-torch.log(sigma) + mu**2 + sigma**2 - 0.5)\n",
    "\n",
    "        return result"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU devices found: 1\n",
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "#We'll use GPU is available; check if a GPU is available\n",
    "print(f'GPU devices found: {torch.cuda.device_count()}')\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'Device: {device}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyAutoencoder(\n",
      "  (encoder): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (mu): Linear(in_features=512, out_features=4, bias=True)\n",
      "  (sigma): Linear(in_features=512, out_features=4, bias=True)\n",
      "  (decoder): Sequential(\n",
      "    (0): Linear(in_features=4, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=784, bias=True)\n",
      "    (3): Sigmoid()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#Create an instance of the model and print; it should display all the layers and their related information\n",
    "model = MyAutoencoder(CHANNELS, WIDTH, HEIGHT).to(device)\n",
    "print(model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28])\n"
     ]
    },
    {
     "data": {
      "text/plain": "tensor([[[[0.4821, 0.5466, 0.4896, 0.5513, 0.4662, 0.4868, 0.4518, 0.4347,\n           0.5025, 0.4456, 0.4709, 0.5344, 0.4508, 0.5570, 0.4362, 0.4423,\n           0.5267, 0.3931, 0.5880, 0.4506, 0.4717, 0.4755, 0.5651, 0.5993,\n           0.5179, 0.5053, 0.4864, 0.4874],\n          [0.4565, 0.4381, 0.5693, 0.4857, 0.6260, 0.5566, 0.5613, 0.5138,\n           0.5568, 0.5430, 0.4678, 0.4952, 0.4597, 0.4990, 0.6136, 0.5007,\n           0.4590, 0.4603, 0.4837, 0.4026, 0.5809, 0.4124, 0.4755, 0.5652,\n           0.4652, 0.3704, 0.4569, 0.5102],\n          [0.4178, 0.4549, 0.5025, 0.5633, 0.4964, 0.6204, 0.5084, 0.6110,\n           0.4652, 0.5645, 0.4421, 0.5307, 0.4126, 0.3894, 0.4673, 0.4064,\n           0.4972, 0.5055, 0.4818, 0.4213, 0.5509, 0.5902, 0.5128, 0.5050,\n           0.5613, 0.4601, 0.4579, 0.4835],\n          [0.4623, 0.5467, 0.4608, 0.5324, 0.5064, 0.5748, 0.4349, 0.5486,\n           0.5439, 0.5672, 0.5554, 0.4483, 0.5860, 0.4919, 0.5381, 0.5443,\n           0.5338, 0.4559, 0.5510, 0.5498, 0.4622, 0.4522, 0.5218, 0.4128,\n           0.4785, 0.4315, 0.5594, 0.4530],\n          [0.4809, 0.5273, 0.4717, 0.6817, 0.5056, 0.5666, 0.5326, 0.4733,\n           0.5018, 0.5427, 0.3841, 0.4557, 0.4082, 0.5149, 0.4668, 0.4893,\n           0.4908, 0.4606, 0.3597, 0.6659, 0.4148, 0.4151, 0.4290, 0.4509,\n           0.4544, 0.5606, 0.5093, 0.4757],\n          [0.4453, 0.5218, 0.4746, 0.4439, 0.4513, 0.6833, 0.6093, 0.6183,\n           0.4947, 0.5453, 0.4328, 0.5121, 0.5340, 0.4415, 0.4726, 0.5300,\n           0.4908, 0.5280, 0.5202, 0.5100, 0.4883, 0.5980, 0.4615, 0.5559,\n           0.4785, 0.5850, 0.5449, 0.6032],\n          [0.4902, 0.5135, 0.5518, 0.4783, 0.6199, 0.4306, 0.5778, 0.5219,\n           0.5356, 0.5369, 0.5162, 0.4942, 0.5403, 0.5432, 0.4220, 0.5488,\n           0.5865, 0.5121, 0.4413, 0.4943, 0.5131, 0.5077, 0.4753, 0.4668,\n           0.6407, 0.5472, 0.4413, 0.4727],\n          [0.5486, 0.5269, 0.6206, 0.5189, 0.5281, 0.4556, 0.5640, 0.4712,\n           0.5334, 0.4678, 0.5439, 0.5965, 0.5520, 0.4901, 0.4889, 0.4257,\n           0.4605, 0.5844, 0.5213, 0.5463, 0.5763, 0.4733, 0.5088, 0.5842,\n           0.5317, 0.5052, 0.5101, 0.4356],\n          [0.4942, 0.5908, 0.5246, 0.5345, 0.5523, 0.5256, 0.5643, 0.4264,\n           0.5384, 0.4940, 0.5076, 0.5662, 0.5473, 0.4933, 0.5430, 0.5163,\n           0.4679, 0.5371, 0.4786, 0.4642, 0.4592, 0.5410, 0.6183, 0.5718,\n           0.4341, 0.5244, 0.4636, 0.4221],\n          [0.4754, 0.5433, 0.4132, 0.5458, 0.6210, 0.5012, 0.5235, 0.4938,\n           0.4524, 0.5456, 0.3221, 0.4374, 0.4984, 0.4806, 0.4766, 0.5378,\n           0.4854, 0.4631, 0.5295, 0.4350, 0.5226, 0.4985, 0.4221, 0.4161,\n           0.4634, 0.3961, 0.4466, 0.5595],\n          [0.5563, 0.5493, 0.5239, 0.5783, 0.4070, 0.5139, 0.4402, 0.5527,\n           0.4491, 0.4157, 0.5800, 0.4243, 0.5482, 0.5732, 0.6076, 0.6472,\n           0.5549, 0.5062, 0.5574, 0.4585, 0.5221, 0.4991, 0.5934, 0.4397,\n           0.4118, 0.4850, 0.5215, 0.4604],\n          [0.3893, 0.6230, 0.5687, 0.4311, 0.4339, 0.5587, 0.5477, 0.4701,\n           0.5219, 0.4866, 0.5354, 0.5339, 0.4723, 0.5246, 0.5179, 0.4886,\n           0.4300, 0.4803, 0.5048, 0.4237, 0.4648, 0.4945, 0.4545, 0.3694,\n           0.4245, 0.4328, 0.5797, 0.4897],\n          [0.4933, 0.5047, 0.5128, 0.5055, 0.3800, 0.4310, 0.4745, 0.5249,\n           0.5667, 0.4756, 0.5029, 0.4013, 0.5250, 0.5279, 0.4784, 0.5621,\n           0.6014, 0.5200, 0.6431, 0.5120, 0.5367, 0.4778, 0.5345, 0.5083,\n           0.4675, 0.4536, 0.5343, 0.4993],\n          [0.4416, 0.5034, 0.5587, 0.5323, 0.4025, 0.5652, 0.5056, 0.5465,\n           0.5142, 0.4763, 0.4397, 0.4720, 0.5313, 0.5211, 0.5747, 0.4466,\n           0.4620, 0.5402, 0.5969, 0.4941, 0.5013, 0.4174, 0.3699, 0.5438,\n           0.5027, 0.4704, 0.4994, 0.5761],\n          [0.5686, 0.4673, 0.4709, 0.4835, 0.5909, 0.4622, 0.5840, 0.4768,\n           0.4721, 0.3002, 0.4323, 0.5074, 0.4948, 0.6135, 0.4849, 0.5255,\n           0.5202, 0.5152, 0.5314, 0.4631, 0.5180, 0.4714, 0.4387, 0.5602,\n           0.6093, 0.5177, 0.6068, 0.4609],\n          [0.4610, 0.5457, 0.3934, 0.5741, 0.5247, 0.5522, 0.4469, 0.5569,\n           0.4942, 0.5579, 0.5095, 0.4929, 0.5620, 0.5258, 0.4450, 0.4839,\n           0.4545, 0.5155, 0.4799, 0.4903, 0.5304, 0.5539, 0.5006, 0.5450,\n           0.6065, 0.5319, 0.4719, 0.4459],\n          [0.5228, 0.4846, 0.5005, 0.4226, 0.3926, 0.3425, 0.6132, 0.4915,\n           0.4505, 0.4200, 0.5559, 0.4868, 0.4529, 0.4636, 0.5559, 0.4827,\n           0.5051, 0.5231, 0.4345, 0.4711, 0.4949, 0.5569, 0.4567, 0.4351,\n           0.5281, 0.4006, 0.5233, 0.4750],\n          [0.5328, 0.5619, 0.5431, 0.5634, 0.5313, 0.5875, 0.5557, 0.5655,\n           0.4929, 0.4210, 0.3511, 0.4216, 0.4106, 0.3914, 0.4446, 0.5186,\n           0.5121, 0.4841, 0.5086, 0.4232, 0.4776, 0.5605, 0.4779, 0.5704,\n           0.6469, 0.5011, 0.5752, 0.4662],\n          [0.5191, 0.4816, 0.4777, 0.6421, 0.5199, 0.4199, 0.4670, 0.5233,\n           0.5598, 0.4523, 0.4692, 0.4583, 0.3904, 0.4593, 0.5884, 0.5167,\n           0.6029, 0.5555, 0.5143, 0.4727, 0.5312, 0.5555, 0.4529, 0.5437,\n           0.5287, 0.3348, 0.5159, 0.4598],\n          [0.4418, 0.5836, 0.6307, 0.4869, 0.4331, 0.4793, 0.4653, 0.4322,\n           0.4843, 0.4558, 0.5065, 0.4059, 0.5121, 0.5380, 0.4824, 0.6118,\n           0.5141, 0.6029, 0.5792, 0.5448, 0.5122, 0.5272, 0.5355, 0.5377,\n           0.4828, 0.4312, 0.4387, 0.6042],\n          [0.5887, 0.4356, 0.5878, 0.5421, 0.5922, 0.4787, 0.5243, 0.5125,\n           0.4104, 0.4125, 0.4093, 0.4835, 0.5000, 0.4838, 0.5138, 0.4246,\n           0.5168, 0.4684, 0.6020, 0.4758, 0.5280, 0.4942, 0.5411, 0.4487,\n           0.5312, 0.4832, 0.4835, 0.5162],\n          [0.4092, 0.4282, 0.5121, 0.4612, 0.4679, 0.5030, 0.5273, 0.4843,\n           0.5636, 0.5227, 0.5765, 0.5628, 0.5272, 0.5518, 0.5094, 0.4592,\n           0.4645, 0.5255, 0.5463, 0.5412, 0.4948, 0.4791, 0.5449, 0.5514,\n           0.4333, 0.5188, 0.5546, 0.4630],\n          [0.4643, 0.3901, 0.4620, 0.5080, 0.5002, 0.5515, 0.4496, 0.4210,\n           0.4149, 0.3984, 0.5084, 0.5093, 0.4912, 0.5486, 0.4777, 0.4847,\n           0.6453, 0.4601, 0.4935, 0.4936, 0.5545, 0.5380, 0.5198, 0.6247,\n           0.4867, 0.5363, 0.5251, 0.4650],\n          [0.4362, 0.6113, 0.4258, 0.4835, 0.5211, 0.5102, 0.6310, 0.5816,\n           0.4688, 0.5422, 0.5137, 0.5440, 0.5182, 0.6042, 0.5129, 0.4400,\n           0.5466, 0.4964, 0.5046, 0.5498, 0.4742, 0.5598, 0.5667, 0.4697,\n           0.4762, 0.5563, 0.4771, 0.4381],\n          [0.5427, 0.5011, 0.4776, 0.5007, 0.4949, 0.4447, 0.3986, 0.5036,\n           0.5279, 0.6108, 0.4520, 0.5518, 0.3671, 0.5266, 0.4795, 0.4859,\n           0.5369, 0.5589, 0.4736, 0.4949, 0.4635, 0.6346, 0.5704, 0.5953,\n           0.4682, 0.4608, 0.5579, 0.5149],\n          [0.5155, 0.5508, 0.5290, 0.4336, 0.4506, 0.4566, 0.4579, 0.5776,\n           0.4667, 0.5599, 0.5518, 0.4474, 0.4887, 0.4737, 0.5718, 0.4524,\n           0.4540, 0.4322, 0.4583, 0.5383, 0.4986, 0.5411, 0.5723, 0.4889,\n           0.5248, 0.4510, 0.5032, 0.5411],\n          [0.4384, 0.4997, 0.4390, 0.5578, 0.5146, 0.4994, 0.4725, 0.5429,\n           0.5251, 0.5573, 0.4627, 0.5147, 0.5397, 0.4522, 0.4603, 0.3927,\n           0.6066, 0.5762, 0.4896, 0.4309, 0.4882, 0.4401, 0.5032, 0.5041,\n           0.4883, 0.4258, 0.4690, 0.5835],\n          [0.4707, 0.5118, 0.4076, 0.3577, 0.5420, 0.4502, 0.3973, 0.5332,\n           0.5026, 0.5438, 0.5760, 0.6031, 0.3617, 0.4632, 0.5265, 0.4898,\n           0.5293, 0.4445, 0.5188, 0.5263, 0.5041, 0.4247, 0.4626, 0.4310,\n           0.5135, 0.5111, 0.5530, 0.5174]]]], device='cuda:0',\n       grad_fn=<ReshapeAliasBackward0>)"
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#SANITY CHECK: Feed forward an image and check for errors\n",
    "#Pull the first image from the training images, and convert to a float tensor\n",
    "img = torch.from_numpy(training_images[0]).float()\n",
    "print(img.shape)\n",
    "\n",
    "#The input to the autoencoder is [batch_size, 3, 32, 32]; convert the image's shape [3,32,32] to [1,3,32,32] and push to device\n",
    "img = torch.reshape(img, (1, CHANNELS, WIDTH, HEIGHT)).to(device)\n",
    "\n",
    "#feed forward the image to the network and make sure it works with no errors\n",
    "model.forward(img)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [],
   "source": [
    "#Switch to 0; otherwise it will load the saved weights\n",
    "if 0:\n",
    "    model.load_state_dict(torch.load(\"trained_weights_linear_MNIST.save\"))\n",
    "    model.eval()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 3618.47753906:  77%|██████████████████████████████▊         | 154/200 [03:51<01:08,  1.48s/it]"
     ]
    }
   ],
   "source": [
    "#TRAINING\n",
    "\n",
    "#define the hyperparameters\n",
    "BATCH_SIZE = 100\n",
    "EPOCHS=200\n",
    "LEARNING_RATE=0.00001\n",
    "\n",
    "\n",
    "#Create an optimizer and pass the model's parameters\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "#Define a loss function; we'll pick mean squared error since we are reconstructing the original\n",
    "loss_function = torch.nn.MSELoss(reduction='sum')\n",
    "\n",
    "#training image indices; [0, 1, 2, 3 ....., 49999]\n",
    "training_dataset_indices = torch.arange(0, len(training_dataset))\n",
    "\n",
    "#keep track of the losses for plotting at the end\n",
    "losses = list()\n",
    "\n",
    "#Create a progress bar the size of the number of epochs\n",
    "status_bar = tqdm.tqdm(range(EPOCHS), ncols=100, desc='loss: ')\n",
    "for i in status_bar:\n",
    "    #At each iteration, perform a permutation of the training_dataset_indices; this ensures that we will use all images and avoid duplication\n",
    "    random_permutation = torch.randperm(training_dataset_indices.size()[0])\n",
    "\n",
    "    #Get BATCH_SIZE number of training images at each epoch; because we sample from an array there will be no duplicates\n",
    "    loss = None\n",
    "    for b in range(0,training_dataset_indices.size()[0], BATCH_SIZE):\n",
    "        #Zero out the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        #Get the indices of the training images in this batch\n",
    "        batch_indices = random_permutation[b:b+BATCH_SIZE]\n",
    "        #we only need to get the images; the labels are irrelevant in the context of an autoencoder\n",
    "        batch_images = training_images[batch_indices]\n",
    "        #convert to float tensors and push to device\n",
    "        batch_images = torch.from_numpy(batch_images).float().to(device)\n",
    "\n",
    "        #feed forward through the network's layers and get the reconstruction\n",
    "        reconstructions = model.forward(batch_images)\n",
    "        \n",
    "        #Calculate the MSE between the reconstructions and the input images plus the KL divergence of the learnt distribution from a zero-mean Gaussian of standard deviation of 1.0; the optimal value for this loss is 0\n",
    "        loss = loss_function(reconstructions, batch_images) + model.getKLdiv()\n",
    "\n",
    "        #keep track of the losses per batch, per epoch it to the list; used for plotting later on\n",
    "        losses.append(loss.item())\n",
    "        \n",
    "        #backpropagate gradients\n",
    "        loss.backward()\n",
    "        #single gradient descent step; update all network parameters based on the gradient\n",
    "        optimizer.step()\n",
    "    \n",
    "    #After every epoch update the loss function\n",
    "    status_bar.set_description(f'loss: {loss.item():.8f}')\n",
    "\n",
    "#Output the final loss on the training dataset\n",
    "print(f'Final loss on training: {loss.item():.8f}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Switch to 0, otherwise it will overwrite the saved weights\n",
    "if 1:\n",
    "    torch.save(model.state_dict(), \"trained_weights_linear_MNIST.save\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Plot the loss as a function of epochs\n",
    "fig, ax = plt.subplots(1,1)\n",
    "ax.plot(list(range(EPOCHS*int(len(training_dataset)/BATCH_SIZE))), np.array(losses))\n",
    "ax.set_title('Loss on training dataset')\n",
    "ax.set_xlabel('epoch')\n",
    "ax.set_ylabel('MSE')\n",
    "plt.show()\n",
    "fig.savefig(\"vae_loss_linear_MNIST.png\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    #Calculate MSE on the testing dataset; convert to float tensors and push to device; I'm passing all the images together since it fits in the GPU\n",
    "    testing_images_ = torch.from_numpy(testing_images[:BATCH_SIZE]).float().reshape( (BATCH_SIZE, CHANNELS, WIDTH, HEIGHT) ).to(device)\n",
    "    #get the reconstructions\n",
    "    reconstructions = model.forward(testing_images_)\n",
    "    testing_loss = loss_function(reconstructions, testing_images_).item()\n",
    "    #Output the MSE loss\n",
    "    print(f'MSE loss on testing: {testing_loss:.8f}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Plot a couple of examples\n",
    "cols, rows = 2, 10\n",
    "image_counter = 1\n",
    "figure = plt.figure(figsize=(3*cols, 3*rows))\n",
    "for i in range(10):\n",
    "    #get a random index\n",
    "    rand_index = random.randint(0, len(testing_images_))\n",
    "    #get the original image, pull back to cpu and convert to numpy\n",
    "    original_img = testing_images_[rand_index].permute(1,2,0).cpu().detach().numpy()\n",
    "    #get the reconstructed image, pull back to cpu and convert to numpy\n",
    "    reconstructed_img = reconstructions[rand_index].permute(1,2,0).cpu().detach().numpy()\n",
    "    \n",
    "    #Add a figure for the original image\n",
    "    figure.add_subplot(rows, cols, image_counter)\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(original_img)\n",
    "    image_counter+=1\n",
    "\n",
    "    #Add a figure for the reconstructed image\n",
    "    figure.add_subplot(rows, cols, image_counter)\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(reconstructed_img)\n",
    "    image_counter+=1\n",
    "\n",
    "plt.show()\n",
    "figure.savefig(\"vae_reconstruction_linear_MNIST.png\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}